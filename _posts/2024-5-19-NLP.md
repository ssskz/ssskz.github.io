---
title: Natural Language Processing
commentable: true
Edit: 2024-5-19
mathjax: true
mermaid: true
tags: python
categories: Artificial-Intelligence
description: NLP, which is short for Natural Language Processing, is an important branch of artificial intelligence.
---

自然语言处理是人工智能的一个子领域，旨在让机器像人类一样理解自然语言。

NLP 技术的力量可以追溯到 1950 年代的图灵测试，该测试用于确定机器是否可以被认为是智能的。

> A computer would deserve to be called intelligent if it could deceive a human into believing that it was human.   ————Alan Turing

# What is NLP

自然语言处理 (NLP) 是计算机科学的一个领域，特别是人工智能 (AI) 的一个子集，专注于使计算机能够像人类一样理解文本和口语。

它需要开发算法和模型，使计算机能够理解、解释和生成书面和口头形式的人类语言。

机器中自然语言处理的任务分为两个子任务：

- **自然语言理解**：不仅旨在处理语言的句法结构，而且还从中导出语义的技术属于此子任务——语音识别、命名实体识别、文本分类。
- **自然语言生成**：从 NLU 派生的知识通过语言生成更进一步。例如 – 问答、文本生成（您在上面读过的 GPT 的诗）、语音生成（在虚拟助手中找到）。 

现在，诸如语言翻译、搜索自动建议之类的NLP应用程序从名称来看可能看起来很简单，但它们是使用一些基本且简单的 NLP 技术的管道开发的。在继续讨论这些技术之前，让我们简要概述一下常用的两种主要类型的 NLP 算法

- **基于规则的系统**：这些算法使用预定义的规则和模式来处理和理解语言。
- **基于机器学习的系统**：这些算法使用统计和机器学习技术从数据中学习，并根据文本中的模式进行预测或分类。

------

# NLP Technology

自然语言处理 (NLP) 用于从文本中提取数据的十大技术是：

## Tokenization

在进行自然语言处理时，分词是最基本和最简单的 NLP 技术之一。在为任何 NLP 应用程序预处理文本时，分词是一个重要步骤。一个长时间运行的文本字符串被分解成更小的单元，称为标记，这些单元构成单词、符号、数字等。这些标记是构建块，有助于在开发 NLP 模型时理解上下文。大多数分词器使用“空格”作为分隔符来形成分词。基于建模的语言和目的，NLP 中使用了多种分词技术

- 基于规则的分词
- 空白分词
- 空间分词器
- 子词分词
- 基于字典的分词
- Penn Tree的分词

在 Python 中实现 Tokenization 技术，我们首先使用 scikit-learn 加载 20newsgroup 文本分类数据集。

```python
 import numpy as np
 print("""This is a python code fence""")
```

```
 This is a simple code fence. You can use it to display text. The fonts are mono spaced.
```

You can mix them as well, like 

> ```
>  This
> ```

## 词干提取和词形还原

Tokenization之后的预处理流程中下一个最重要的 NLP 技术是词干化或词形还原。

例如，当我们在亚马逊上搜索产品时，假设我们不仅希望看到我们在搜索栏中输入的确切单词的产品，还希望看到我们输入的单词的其他可能形式的产品。如果我们在搜索框中输入“衬衫”，那么我们很可能希望看到包含“衬衫”形式的产品结果。在英语中，相似的单词根据其使用的时态及其在句子中的位置而出现不同的情况。例如，go、going、went 等单词都是相同的单词，但根据句子的上下文使用。

词干提取或词形还原 NLP 技术旨在从单词的这些变体生成词根。词干提取是一种粗略的启发式过程，它试图通过切断单词的结尾来实现上述目标，最终可能会或可能不会产生有意义的单词。

另一方面，词形还原是一种更复杂的技术，旨在通过使用词汇和词的形态分析来正确地做事。通过删除屈折词尾，它返回称为词条的单词的基本形式或字典形式。

## 停用词去除

词干化或词形还原之后的预处理步骤是停用词删除。在任何语言中，很多单词只是填充词，没有任何附加意义。这些主要是用来连接句子的词（连词——“because”、“and”、“since”）或用来表示一个词与其他词的关系（介词——“under”、“above”、in、in、 “在”） 。这些单词构成了人类语言的大部分，在开发 NLP 模型时并没有真正的用处。

然而，停用词移除并不是针对每个模型实施的明确 NLP 技术，因为它取决于任务。例如，在进行文本分类时，如果需要将文本分为不同的类别（类型分类、过滤垃圾邮件、自动标记生成）然后从文本中删除停用词会很有帮助，因为模型可以专注于定义数据集中文本含义的单词。对于类似的任务文本摘要和机器翻译，可能不需要删除停用词。有多种方法可以使用 Genism、SpaCy 和 NLTK 等库来删除停用词。我们将使用SpaCy库来了解停用词删除 NLP 技术。SpaCy 提供了大多数语言的停用词列表。

## TF-IDF

TF-IDF 本质是一种统计技术，用于说明单词对于文档集合中的文档的重要性。TF-IDF 统计度量是通过乘以 2 个不同的值（术语频率和逆文档频率）来计算的。

### 词频

词频用于计算单词在文档中出现的频率。它由以下公式给出

通常出现在文档中的单词（例如停用词）——“the”、“is”、“will”将具有很高的术语频率。

### 逆向文档频率

在讨论逆文档频率之前，让我们首先了解文档频率。在多个文档的语料库中，文档频率衡量一个单词在整个文档语料库中的出现次数（N）。

对于我们之前讨论过的常用英语单词来说，这个值会很高。逆文档频率与文档频率正好相反。

这基本上衡量了我们语料库中术语的有用性。特定于特定文档的术语将具有较高的 IDF。生物医学、基因组等术语只会出现在与生物学相关的文档中，并且具有较高的 IDF。

TF-IDF 背后的整体思想是通过查找文档中出现频率较高但在语料库中其他位置不出现的单词来查找文档中的重要单词。对于与计算机科学相关的文档，这些词可能是 - 计算、数据、处理器等。但对于天文文档，则可能是 - 外星人、银河系、黑洞等。现在，让我们了解 TF-IDF NLP 技术一个使用 Python 中的 Scikit-learn 库的示例。

## 关键词提取

当你在手机、报纸或书本上阅读一段文字时，你会进行这种不自觉的浏览活动——你大多会忽略填充词，并从文本中找到重要的单词，而其他所有内容都符合上下文。关键字提取与在文档中查找重要关键字的作用完全相同。

关键词提取是一种文本分析NLP技术可在短时间内获得对某个主题有意义的见解。不必浏览文档，可以使用关键词提取技术来简洁文本并提取相关关键词。关键字提取技术在 NLP 应用程序中非常有用，在这种应用程序中，企业想要根据评论识别客户遇到的问题，或者如果您想要从最近的新闻项目中识别感兴趣的主题。

## 词嵌入

正如我们所知，机器学习和深度学习算法只接受数字输入，那么我们如何将一段文本转换为可以提供给这些模型的数字。在对文本数据训练任何类型的模型时，无论是分类还是回归，将其转换为数字表示是必要条件。答案很简单，遵循词嵌入方法来表示文本数据。这种 NLP 技术可以让您表示具有相似含义的单词，从而获得相似的表示。

词嵌入也称为向量，是语言中单词的数字表示。这些表示的学习使得具有相似含义的单词的向量彼此非常接近。单个单词被表示为实值向量或预定义的 n 维向量空间中的坐标。 这没有多大意义，不是吗？让我们用一个例子来理解这一点。

## 情感分析

情感分析也称为情感 AI 或观点挖掘，是文本分类最重要的 NLP 技术之一。目标是将推文、新闻文章、电影评论或网络上的任何文本等文本分类为这 3 个类别之一：正面/负面/中立。情绪分析最常用于减少社交媒体平台上的仇恨言论，并从负面评论中识别出陷入困境的客户。

## 主题建模

主题建模是一种统计 NLP 技术，可分析文本文档语料库以查找隐藏在其中的主题。最好的部分是，主题建模是一种无监督机器学习算法，这意味着它不需要对这些文档进行标记。这项技术使我们能够以人工注释无法达到的规模来组织和总结电子档案。潜在狄利克雷分配是用于主题建模的最强大的技术之一。基本直觉是每个文档都有多个主题，每个主题分布在固定的词汇表上。让我们通过一个例子来理解这一点。

## 文本摘要

这种 NLP 技术用于以流畅、连贯的方式简洁、简短地总结文本。摘要对于从文档中提取有用信息非常有用，而无需逐字阅读。如果由人来完成，这个过程非常耗时，自动文本摘要从根本上减少了时间。

目前有两种类型的文本摘要技术：

- 基于提取的摘要：在这种技术中，提取文档中的一些关键短语和单词来进行摘要。对原文没有做任何改动。
- 基于抽象的摘要：在这种文本摘要技术中，从捕获最有用信息的原始文档中创建新的短语和句子。摘要的语言和句子结构与原始文档不同，因为这种技术涉及释义。我们还可以克服基于提取的方法中发现的语法不一致。

## 命名实体识别

NER是信息提取的一个子领域，它处理从非结构化文档中定位命名实体并将其分类为预定义的类别，如人名、组织、位置、事件、日期等。NER 在某种程度上类似于关键字提取，只不过提取的关键字被放入已经定义的类别中。这确实比我们在关键字提取方面领先一步。Spacy 中有内置函数可以执行此操作。我们将使用一篇文章的新摘录。

# Images

Markdown uses `![caption](link)` to reference pictures, caption is optional. You cannot control the size. 

![caption](https://raw.githubusercontent.com/yk-liu/yk-liu.github.io/master/_posts/2018-11-01-Introduction-to-Homology/assets/triangles.png)

So I prefer using HTML tags like this:

<img src="https://raw.githubusercontent.com/yk-liu/yk-liu.github.io/master/_posts/2018-11-01-Introduction-to-Homology/assets/triangles.png" width="30%">

# Lists

- List can have multiple lines

  like this.

------

1. This ordered list
   1. sub item
2. This is as well
3. It can keep going

------

1. You can avoid numbers like this
   1. sub item
1. It keeps going
1. Blah Blah

*This is italic.* **This is Bold**. * If asterisk is surrounded by spaces, it is not parsed. *

_This is also italic._ __This is also Bold__. _ If underscore is surrounded by spaces, it is not parsed. _

~~This is strike through~~. 

There is no underline in markdown. You can use html tags <u>like this to underline.</u>

`This is a code block`. 

[This is an external link](https://bit.ly). "https://" is important. This is an internal [link](#this-is-a-h2). Internal links are all lowercase with space replaced by hyphens "-". 

You can mix them like [*this*](https://bit.ly), [`this`](https://bit.ly), **[this](https://bit.ly)**, but not like `[this](https://bit.ly)`.


# Tables

| This column is left aligned | This column is centered | This column is right aligned |
| :-------------------------- | :---------------------: | ---------------------------: |
| 1                           |            4            |                            7 |
| 2                           |            5            |                            8 |
| 3                           |            6            |                            9 |

| You can use `![caption](link)` in tables.                    | You can use Math in tables. | You can use `<img src="" width="">` in tables.               |
| ------------------------------------------------------------ | --------------------------- | ------------------------------------------------------------ |
| ![caption](https://raw.githubusercontent.com/yk-liu/yk-liu.github.io/master/_posts/2018-11-01-Introduction-to-Homology/assets/triangles.png) | $1+1=2$                     | <img src="https://raw.githubusercontent.com/yk-liu/yk-liu.github.io/master/_posts/2018-11-01-Introduction-to-Homology/assets/triangles.png" width="30%"> |

# Foot Notes

This is a note[^1]. Footnotes can have captions like[^this]. You can reference to the same note multiple times like[^this]. Foot notes can have many other options like[^this-one]. Or just like [^that]. This is a [reference style link][linkid] to a page. And [this][linkid] is also a link. As is [this][] and [that].

# Foot Notes

The Foot notes are like this

[^1]: https://ssskz.github.io
[^this]: https://ssskz.github.io
[^this-one]: 

```
> Blockquotes can be in a footnote.
```

```
    as well as code blocks
```

[^that]: or, naturally, simple paragraphs.

[linkid]: https://ssskz.github.io	"Optional Title"
